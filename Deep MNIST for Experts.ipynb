{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mayojich/TensorFlow/blob/master/Deep%20MNIST%20for%20Experts.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_BcHafE_qEWV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Deep MNIST for Experts](https://www.tensorflow.org/versions/r1.2/get_started/mnist/pros)  \n",
        "- Read up on ReLu"
      ]
    },
    {
      "metadata": {
        "id": "8Ff2ZWKvbIId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SETUP**"
      ]
    },
    {
      "metadata": {
        "id": "QmEYAJV4a3I2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load MNIST Data**"
      ]
    },
    {
      "metadata": {
        "id": "vmsvOXYrawxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kltYh-Qaa7v1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Start TensorFlow InteractiveSession**"
      ]
    },
    {
      "metadata": {
        "id": "wDMID92Pax3Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbVfO1GjbNQ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**BUILD A SOFTMAX REGRESSION MODEL**"
      ]
    },
    {
      "metadata": {
        "id": "7SMKXheAbVwt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Placeholders**"
      ]
    },
    {
      "metadata": {
        "id": "XWgz6FqJbZON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input images and target output classes\n",
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQfXIRO8bbCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Variables**"
      ]
    },
    {
      "metadata": {
        "id": "uS5YLrKmbcuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# W(weights) and b(biases) are handled as variables\n",
        "W = tf.Variable(tf.zeros([784,10]))\n",
        "b = tf.Variable(tf.zeros([10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GxF27WL5bekB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize session to use all variables\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mI5EGAGKbgWc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Predicted Class and Loss Function**"
      ]
    },
    {
      "metadata": {
        "id": "h7JN3VIcbmqC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# regression model\n",
        "y = tf.matmul(x,W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXZQ7pXiboKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce loss. Second line applies softmax\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EWB3nCtmbph3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TRAIN THE MODEL**"
      ]
    },
    {
      "metadata": {
        "id": "xaQycqp0bwET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tensorflow uses optimization algos. Gradient descent = 0.5\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCruwJXtbx__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# repeat train_step in batches of 100. feed_dict replaces placeholders x and y_\n",
        "for _ in range(1000):\n",
        "  batch = mnist.train.next_batch(100)\n",
        "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5d8G7DSbzTj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model**"
      ]
    },
    {
      "metadata": {
        "id": "jE-aStyRcNPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.argmax(y, 1) is label of model\n",
        "# tf.argmax(y_,1) is the truth\n",
        "# tf.equal checks prediction accuracy against truth\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZBpr3ewJcOkJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DzYuH7N2cQFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# accuracy of test data\n",
        "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v1AuVpzycTUR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**BUILD A MULTILAYER CONVOLUTIONAL NETWORK**"
      ]
    },
    {
      "metadata": {
        "id": "CjKkRPMxcYRp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Weight Initialization**  \n",
        "Use convolutional neural network to up 92% accuracy to 99.2%."
      ]
    },
    {
      "metadata": {
        "id": "yw44PCM3chR-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# functions will run W and b. W has small noise. b is slightly +ve biased.\n",
        "def weight_variable(shape):\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "  initial = tf.constant(0.1, shape=shape)\n",
        "  return tf.Variable(initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8UCAcKq0cmFe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convolution and Pooling**"
      ]
    },
    {
      "metadata": {
        "id": "ycSLvfpmcoW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bq64_xhMcpg2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**First Convolutional Layer**"
      ]
    },
    {
      "metadata": {
        "id": "bPn8Smr7cwwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convolution has 32 features for each 5x5 patch.\n",
        "# 1d and 2d(patch size), 3d(number of input channels), 4d(number of output channels)\n",
        "W_conv1 = weight_variable([5, 5, 1, 32])\n",
        "b_conv1 = bias_variable([32])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CN1ZKTIscu7e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2d and 3d(image width and height), 4d(number of color channels)\n",
        "x_image = tf.reshape(x, [-1, 28, 28, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qAX4fc5fczqY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convolve x_image with the weight tensor, add the bias, apply the ReLU function\n",
        "# max_pool_2x2 reduces size to 14x14\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
        "h_pool1 = max_pool_2x2(h_conv1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrmahTpic0nz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Second Convolutional Layer**"
      ]
    },
    {
      "metadata": {
        "id": "8WX4g3vAc628",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 64 features for each 5x5 patch\n",
        "W_conv2 = weight_variable([5, 5, 32, 64])\n",
        "b_conv2 = bias_variable([64])\n",
        "\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1HZYbT8c8TN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Densely Connected Layer**"
      ]
    },
    {
      "metadata": {
        "id": "lyWxsgm2dALL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce image size to 7x7. 1024 neurons to process image. \n",
        "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
        "b_fc1 = bias_variable([1024])\n",
        "\n",
        "# reshape tensor from pooling layer into vectors, multiple weight matrix, add bias, apply ReLu.\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vo8bREa6dFMl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Dropout*  \n",
        "To reduce overfitting"
      ]
    },
    {
      "metadata": {
        "id": "jik8hFfrdH2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# placeholder turns on dropout during training, turns off during testing\n",
        "# tf.nn.dropout handles scaling neuron outputs\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xiZttnsGdJe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Readout Layer**"
      ]
    },
    {
      "metadata": {
        "id": "mfdyQyEUdNnr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add a layer\n",
        "W_fc2 = weight_variable([1024, 10])\n",
        "b_fc2 = bias_variable([10])\n",
        "\n",
        "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WOVdX_odS9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train and Evaluate the Model**"
      ]
    },
    {
      "metadata": {
        "id": "gqTMrP5SdZvT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train and evaluate with additional stuff\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(20000):\n",
        "    batch = mnist.train.next_batch(50)\n",
        "    if i % 100 == 0:\n",
        "      train_accuracy = accuracy.eval(feed_dict={\n",
        "          x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
        "      print('step %d, training accuracy %g' % (i, train_accuracy))\n",
        "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
        "\n",
        "  print('test accuracy %g' % accuracy.eval(feed_dict={\n",
        "      x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}